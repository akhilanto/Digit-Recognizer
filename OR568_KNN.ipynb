{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN classifier for Digit recognization kaggle challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.read_csv(\"test.csv\")\n",
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_data = train_data['label']\n",
    "predictor_data = train_data.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data samples creation (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # Random sampling with seed(randomstate)\n",
    "r_predictor_train, r_predictor_test, r_response_train, r_response_test = train_test_split(predictor_data, response_data, random_state=1084203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sets = {'train_predictor':r_predictor_train, 'train_response':r_response_train, 'test_predictor':r_predictor_test, 'test_response':r_response_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data samples creation (K-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold_obj = KFold(n_splits=10, random_state=18)\n",
    "Kfold_samples = [{'train': train_data.iloc[train_index], 'test': train_data.iloc[test_index]} for train_index,test_index in kfold_obj.split(train_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model creation for KNN (30 KNN models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n = 30\n",
    "KNN_objs = [KNeighborsClassifier(n_neighbors=n) for n in range(1,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_objs = [obj.fit(r_predictor_train, r_response_train) for obj in KNN_objs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_predicted = [obj.predict(r_predictor_test) for obj in  KNN_objs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r_response_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-14bf82331e31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_response_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_hat_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNN_predicted\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNN_objs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r_response_test' is not defined"
     ]
    }
   ],
   "source": [
    "response = r_response_test\n",
    "y_hat_array = KNN_predicted\n",
    "model = KNN_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      1025\n",
      "          1       0.97      0.99      0.98      1170\n",
      "          2       0.98      0.96      0.97      1045\n",
      "          3       0.96      0.94      0.95      1091\n",
      "          4       0.97      0.96      0.96      1077\n",
      "          5       0.95      0.97      0.96       957\n",
      "          6       0.97      0.99      0.98      1057\n",
      "          7       0.96      0.98      0.97      1064\n",
      "          8       0.98      0.92      0.95       997\n",
      "          9       0.94      0.96      0.95      1017\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      1025\n",
      "          1       0.95      1.00      0.97      1170\n",
      "          2       0.97      0.97      0.97      1045\n",
      "          3       0.93      0.96      0.95      1091\n",
      "          4       0.95      0.97      0.96      1077\n",
      "          5       0.94      0.95      0.95       957\n",
      "          6       0.98      0.98      0.98      1057\n",
      "          7       0.95      0.97      0.96      1064\n",
      "          8       0.99      0.88      0.93       997\n",
      "          9       0.97      0.92      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.96      0.99      0.98      1170\n",
      "          2       0.98      0.96      0.97      1045\n",
      "          3       0.96      0.95      0.96      1091\n",
      "          4       0.97      0.96      0.96      1077\n",
      "          5       0.96      0.97      0.96       957\n",
      "          6       0.98      0.98      0.98      1057\n",
      "          7       0.95      0.97      0.96      1064\n",
      "          8       0.99      0.93      0.96       997\n",
      "          9       0.95      0.95      0.95      1017\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      1025\n",
      "          1       0.95      0.99      0.97      1170\n",
      "          2       0.98      0.96      0.97      1045\n",
      "          3       0.95      0.96      0.96      1091\n",
      "          4       0.97      0.97      0.97      1077\n",
      "          5       0.95      0.97      0.96       957\n",
      "          6       0.98      0.98      0.98      1057\n",
      "          7       0.95      0.97      0.96      1064\n",
      "          8       0.99      0.92      0.95       997\n",
      "          9       0.96      0.94      0.95      1017\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      1025\n",
      "          1       0.95      0.99      0.97      1170\n",
      "          2       0.98      0.96      0.97      1045\n",
      "          3       0.96      0.96      0.96      1091\n",
      "          4       0.97      0.96      0.97      1077\n",
      "          5       0.96      0.97      0.97       957\n",
      "          6       0.97      0.99      0.98      1057\n",
      "          7       0.95      0.97      0.96      1064\n",
      "          8       0.99      0.93      0.96       997\n",
      "          9       0.95      0.96      0.95      1017\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.95      0.99      0.97      1170\n",
      "          2       0.98      0.96      0.97      1045\n",
      "          3       0.95      0.96      0.95      1091\n",
      "          4       0.97      0.96      0.97      1077\n",
      "          5       0.96      0.97      0.96       957\n",
      "          6       0.97      0.99      0.98      1057\n",
      "          7       0.95      0.97      0.96      1064\n",
      "          8       0.99      0.91      0.95       997\n",
      "          9       0.95      0.95      0.95      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.94      0.99      0.97      1170\n",
      "          2       0.98      0.95      0.97      1045\n",
      "          3       0.96      0.95      0.96      1091\n",
      "          4       0.97      0.95      0.96      1077\n",
      "          5       0.96      0.96      0.96       957\n",
      "          6       0.97      0.99      0.98      1057\n",
      "          7       0.95      0.97      0.96      1064\n",
      "          8       0.99      0.92      0.95       997\n",
      "          9       0.94      0.96      0.95      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      1025\n",
      "          1       0.94      0.99      0.97      1170\n",
      "          2       0.98      0.95      0.97      1045\n",
      "          3       0.95      0.96      0.95      1091\n",
      "          4       0.97      0.96      0.97      1077\n",
      "          5       0.96      0.96      0.96       957\n",
      "          6       0.97      0.99      0.98      1057\n",
      "          7       0.95      0.97      0.96      1064\n",
      "          8       0.99      0.91      0.95       997\n",
      "          9       0.95      0.95      0.95      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.94      0.99      0.97      1170\n",
      "          2       0.98      0.95      0.96      1045\n",
      "          3       0.96      0.95      0.96      1091\n",
      "          4       0.98      0.95      0.96      1077\n",
      "          5       0.96      0.97      0.97       957\n",
      "          6       0.97      0.99      0.98      1057\n",
      "          7       0.94      0.97      0.96      1064\n",
      "          8       0.99      0.91      0.95       997\n",
      "          9       0.94      0.96      0.95      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      1025\n",
      "          1       0.94      0.99      0.97      1170\n",
      "          2       0.98      0.95      0.96      1045\n",
      "          3       0.96      0.95      0.96      1091\n",
      "          4       0.98      0.96      0.97      1077\n",
      "          5       0.96      0.97      0.97       957\n",
      "          6       0.97      0.99      0.98      1057\n",
      "          7       0.94      0.97      0.96      1064\n",
      "          8       0.99      0.91      0.95       997\n",
      "          9       0.94      0.95      0.95      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.94      0.99      0.96      1170\n",
      "          2       0.98      0.94      0.96      1045\n",
      "          3       0.96      0.95      0.96      1091\n",
      "          4       0.98      0.95      0.96      1077\n",
      "          5       0.96      0.96      0.96       957\n",
      "          6       0.97      0.99      0.98      1057\n",
      "          7       0.94      0.97      0.95      1064\n",
      "          8       0.99      0.91      0.95       997\n",
      "          9       0.94      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.93      0.99      0.96      1170\n",
      "          2       0.98      0.94      0.96      1045\n",
      "          3       0.96      0.95      0.96      1091\n",
      "          4       0.98      0.95      0.96      1077\n",
      "          5       0.96      0.96      0.96       957\n",
      "          6       0.97      0.99      0.98      1057\n",
      "          7       0.94      0.97      0.95      1064\n",
      "          8       0.99      0.92      0.95       997\n",
      "          9       0.94      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.93      0.99      0.96      1170\n",
      "          2       0.98      0.94      0.96      1045\n",
      "          3       0.96      0.95      0.95      1091\n",
      "          4       0.98      0.95      0.96      1077\n",
      "          5       0.96      0.96      0.96       957\n",
      "          6       0.96      0.99      0.98      1057\n",
      "          7       0.94      0.97      0.95      1064\n",
      "          8       0.99      0.91      0.95       997\n",
      "          9       0.94      0.95      0.95      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.93      0.99      0.96      1170\n",
      "          2       0.98      0.93      0.96      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.95      0.96      1077\n",
      "          5       0.96      0.96      0.96       957\n",
      "          6       0.96      0.99      0.98      1057\n",
      "          7       0.94      0.97      0.95      1064\n",
      "          8       0.99      0.91      0.95       997\n",
      "          9       0.94      0.95      0.95      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.93      0.99      0.96      1170\n",
      "          2       0.98      0.93      0.96      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.95      0.96      1077\n",
      "          5       0.95      0.96      0.96       957\n",
      "          6       0.96      0.99      0.98      1057\n",
      "          7       0.94      0.97      0.95      1064\n",
      "          8       0.98      0.91      0.94       997\n",
      "          9       0.94      0.95      0.95      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.93      0.99      0.96      1170\n",
      "          2       0.98      0.93      0.96      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.95      0.96      1077\n",
      "          5       0.95      0.96      0.95       957\n",
      "          6       0.96      0.99      0.98      1057\n",
      "          7       0.94      0.97      0.95      1064\n",
      "          8       0.98      0.91      0.94       997\n",
      "          9       0.94      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.93      0.99      0.96      1170\n",
      "          2       0.99      0.93      0.96      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.96      1077\n",
      "          5       0.95      0.96      0.96       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.94      0.97      0.95      1064\n",
      "          8       0.98      0.91      0.94       997\n",
      "          9       0.94      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.93      0.99      0.96      1170\n",
      "          2       0.99      0.93      0.96      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.95      0.96      1077\n",
      "          5       0.96      0.95      0.96       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.94      0.97      0.95      1064\n",
      "          8       0.98      0.90      0.94       997\n",
      "          9       0.94      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.93      0.99      0.96      1170\n",
      "          2       0.99      0.93      0.96      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.96      1077\n",
      "          5       0.95      0.96      0.96       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.93      0.97      0.95      1064\n",
      "          8       0.98      0.90      0.94       997\n",
      "          9       0.93      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.92      0.99      0.96      1170\n",
      "          2       0.99      0.93      0.96      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.96      1077\n",
      "          5       0.96      0.96      0.96       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.93      0.97      0.95      1064\n",
      "          8       0.98      0.90      0.94       997\n",
      "          9       0.93      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1025\n",
      "          1       0.92      0.99      0.96      1170\n",
      "          2       0.99      0.92      0.95      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.95      1077\n",
      "          5       0.96      0.96      0.96       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.93      0.96      0.95      1064\n",
      "          8       0.98      0.90      0.94       997\n",
      "          9       0.92      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.92      0.99      0.96      1170\n",
      "          2       0.99      0.92      0.95      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.96      1077\n",
      "          5       0.95      0.96      0.96       957\n",
      "          6       0.96      0.98      0.97      1057\n",
      "          7       0.93      0.96      0.95      1064\n",
      "          8       0.98      0.90      0.94       997\n",
      "          9       0.93      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.92      0.99      0.96      1170\n",
      "          2       0.99      0.92      0.95      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.96      1077\n",
      "          5       0.95      0.96      0.96       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.93      0.96      0.95      1064\n",
      "          8       0.98      0.90      0.94       997\n",
      "          9       0.93      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.92      0.99      0.96      1170\n",
      "          2       0.99      0.92      0.95      1045\n",
      "          3       0.94      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.96      1077\n",
      "          5       0.95      0.96      0.96       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.93      0.96      0.95      1064\n",
      "          8       0.99      0.90      0.94       997\n",
      "          9       0.93      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.92      0.99      0.95      1170\n",
      "          2       0.99      0.92      0.95      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.96      1077\n",
      "          5       0.95      0.96      0.96       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.93      0.96      0.95      1064\n",
      "          8       0.99      0.90      0.94       997\n",
      "          9       0.93      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.95      0.95     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.92      0.99      0.95      1170\n",
      "          2       0.99      0.92      0.95      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.96      1077\n",
      "          5       0.95      0.96      0.95       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.93      0.96      0.95      1064\n",
      "          8       0.98      0.89      0.94       997\n",
      "          9       0.93      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.96      0.95      0.95     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.92      0.99      0.95      1170\n",
      "          2       0.99      0.92      0.95      1045\n",
      "          3       0.95      0.94      0.94      1091\n",
      "          4       0.97      0.94      0.95      1077\n",
      "          5       0.95      0.96      0.95       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.93      0.96      0.95      1064\n",
      "          8       0.98      0.89      0.94       997\n",
      "          9       0.92      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.91      0.99      0.95      1170\n",
      "          2       0.99      0.92      0.95      1045\n",
      "          3       0.95      0.95      0.95      1091\n",
      "          4       0.97      0.94      0.95      1077\n",
      "          5       0.95      0.96      0.95       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.94      0.96      0.95      1064\n",
      "          8       0.98      0.89      0.94       997\n",
      "          9       0.93      0.95      0.94      1017\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1025\n",
      "          1       0.91      0.99      0.95      1170\n",
      "          2       0.99      0.92      0.95      1045\n",
      "          3       0.95      0.94      0.94      1091\n",
      "          4       0.97      0.94      0.95      1077\n",
      "          5       0.94      0.96      0.95       957\n",
      "          6       0.96      0.99      0.97      1057\n",
      "          7       0.93      0.96      0.95      1064\n",
      "          8       0.98      0.89      0.94       997\n",
      "          9       0.92      0.95      0.93      1017\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10500\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-9c3255060c26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "for i in range(29):\n",
    "    print(classification_report(response, y_hat_array[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model-0 AUC- 0.9796465983583312\n",
      "KNN model-1 AUC- 0.9691098629011746\n",
      "KNN model-2 AUC- 0.9773696365622858\n",
      "KNN model-3 AUC- 0.9757150688635909\n",
      "KNN model-4 AUC- 0.9790713828222962\n",
      "KNN model-5 AUC- 0.9783596605258843\n",
      "KNN model-6 AUC- 0.9779194482576128\n",
      "KNN model-7 AUC- 0.9784008251167462\n",
      "KNN model-8 AUC- 0.9805248972673866\n",
      "KNN model-9 AUC- 0.978009398591549\n",
      "KNN model-10 AUC- 0.9767996573281111\n",
      "KNN model-11 AUC- 0.975847272524419\n",
      "KNN model-12 AUC- 0.9777337928421516\n",
      "KNN model-13 AUC- 0.9775003367305009\n",
      "KNN model-14 AUC- 0.9768740024456122\n",
      "KNN model-15 AUC- 0.9773886635205307\n",
      "KNN model-16 AUC- 0.9759577533092132\n",
      "KNN model-17 AUC- 0.9773369226368026\n",
      "KNN model-18 AUC- 0.9765258142941917\n",
      "KNN model-19 AUC- 0.9753482685105086\n",
      "KNN model-20 AUC- 0.9738423910468156\n",
      "KNN model-21 AUC- 0.9745400634639787\n",
      "KNN model-22 AUC- 0.9754681331629929\n",
      "KNN model-23 AUC- 0.9752788486274305\n",
      "KNN model-24 AUC- 0.9756103428263856\n",
      "KNN model-25 AUC- 0.9755472479811982\n",
      "KNN model-26 AUC- 0.9742742044942816\n",
      "KNN model-27 AUC- 0.9743029782322266\n",
      "KNN model-28 AUC- 0.9732331136264025\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "for i in range(29):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(r_response_test ,y_hat_array[i] ,pos_label=9)\n",
    "    print(\"KNN model-{} AUC- {}\".format(i, metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for plot ROC and precision curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = [model[i].predict_proba(r_predictor_test) for i in range(len(model))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predict = [model[i].predict(validation_data) for i in  range(len(model))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For plotting the ROC and Precision plots use *Prediction_load.kaggle* and *probs30.data* in a python interpreter and execute the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9621038540904625\n",
      "0.9556409488156542\n",
      "0.9622078785457903\n",
      "0.9621006843563814\n",
      "0.9629485613516171\n",
      "0.9605125498254945\n",
      "0.9594541425596179\n",
      "0.9601947577342856\n",
      "0.9595604259639164\n",
      "0.9594541589113861\n",
      "0.9575485105183358\n",
      "0.9574422328218386\n",
      "0.9563836641315486\n",
      "0.9556416849952865\n",
      "0.9539484818667119\n",
      "0.9531010722457035\n",
      "0.9531012505133379\n",
      "0.9527828933844387\n",
      "0.9517247229974083\n",
      "0.9510891092203583\n",
      "0.9501364323874171\n",
      "0.9503480110877242\n",
      "0.9507718241938381\n",
      "0.9503478103369234\n",
      "0.9499247994806577\n",
      "0.9491830453626923\n",
      "0.9480189110135783\n",
      "0.9480185153097849\n",
      "0.9465368480847941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "for i in range(len(model)):\n",
    "        print(cohen_kappa_score(r_response_test, y_hat_array[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9659047619047619\n",
      "0.9600952380952381\n",
      "0.966\n",
      "0.9659047619047619\n",
      "0.9666666666666667\n",
      "0.9644761904761905\n",
      "0.9635238095238096\n",
      "0.9641904761904762\n",
      "0.9636190476190476\n",
      "0.9635238095238096\n",
      "0.9618095238095238\n",
      "0.9617142857142857\n",
      "0.9607619047619048\n",
      "0.9600952380952381\n",
      "0.9585714285714285\n",
      "0.9578095238095238\n",
      "0.9578095238095238\n",
      "0.9575238095238096\n",
      "0.9565714285714285\n",
      "0.956\n",
      "0.9551428571428572\n",
      "0.9553333333333334\n",
      "0.9557142857142857\n",
      "0.9553333333333334\n",
      "0.954952380952381\n",
      "0.9542857142857143\n",
      "0.9532380952380952\n",
      "0.9532380952380952\n",
      "0.9519047619047619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in range(len(model)):\n",
    "        print(accuracy_score(r_response_test, y_hat_array[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predict_vali=KNN_objs[0].predict(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(knn_predict_vali, columns =['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.reset_index(inplace=True)\n",
    "output.rename(columns={'index': 'ImageId'}, inplace=True)\n",
    "output['ImageId']=output['ImageId']+1\n",
    "output.to_csv('output_knn_latest.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
